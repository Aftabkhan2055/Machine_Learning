{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression,Ridge,Lasso\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import mode\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC,SVR,SVC,LinearSVR\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "powers = [1e-4,1e-3,1e-2,1e-1,1,1e1,1e2,1e3,1e4]\n",
    "zoomed = np.array(range(1,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-f746135b0166>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-f746135b0166>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Bank-\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Bank-\n",
    "no of transaction-y\n",
    "bamk balance -x1\n",
    "age-x2\n",
    "retirement status-x3\n",
    "\n",
    "\n",
    "y=a1*x1+a2*x2+a3*x3+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_value(old_value,slope,lr=0.002):\n",
    "    return old_value-lr*slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.964"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_value(2,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits=datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(digits['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0].reshape(8,8),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showRandomImage():\n",
    "    index = np.random.randint(x.shape[0])\n",
    "    plt.imshow(x[index].reshape(8,8),cmap='gray')\n",
    "    plt.show()\n",
    "    print(y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "showRandomImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits['images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100,activation='relu',input_shape=(64,)))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat=to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 22:02:46.211424 13476 deprecation.py:323] From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0822 22:02:46.310192 13476 deprecation_wrapper.py:119] From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1257 samples, validate on 540 samples\n",
      "Epoch 1/20\n",
      "1257/1257 [==============================] - 1s 778us/step - loss: 1.0723 - acc: 0.6698 - val_loss: 0.4333 - val_acc: 0.8648\n",
      "Epoch 2/20\n",
      "1257/1257 [==============================] - 0s 85us/step - loss: 0.1860 - acc: 0.9427 - val_loss: 0.2735 - val_acc: 0.9241\n",
      "Epoch 3/20\n",
      "1257/1257 [==============================] - 0s 93us/step - loss: 0.1086 - acc: 0.9706 - val_loss: 0.3142 - val_acc: 0.9056\n",
      "Epoch 4/20\n",
      "1257/1257 [==============================] - 0s 164us/step - loss: 0.0662 - acc: 0.9825 - val_loss: 0.2393 - val_acc: 0.9407\n",
      "Epoch 5/20\n",
      "1257/1257 [==============================] - 0s 163us/step - loss: 0.0430 - acc: 0.9936 - val_loss: 0.2259 - val_acc: 0.9444\n",
      "Epoch 6/20\n",
      "1257/1257 [==============================] - 0s 165us/step - loss: 0.0333 - acc: 0.9944 - val_loss: 0.2161 - val_acc: 0.9463\n",
      "Epoch 7/20\n",
      "1257/1257 [==============================] - 0s 161us/step - loss: 0.0227 - acc: 0.9992 - val_loss: 0.2228 - val_acc: 0.9426\n",
      "Epoch 8/20\n",
      "1257/1257 [==============================] - 0s 163us/step - loss: 0.0179 - acc: 0.9992 - val_loss: 0.2235 - val_acc: 0.9389\n",
      "Epoch 9/20\n",
      "1257/1257 [==============================] - 0s 177us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.2299 - val_acc: 0.9426\n",
      "Epoch 10/20\n",
      "1257/1257 [==============================] - 0s 176us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.2396 - val_acc: 0.9370\n",
      "Epoch 11/20\n",
      "1257/1257 [==============================] - 0s 172us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.2248 - val_acc: 0.9407\n",
      "Epoch 12/20\n",
      "1257/1257 [==============================] - 0s 182us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.2233 - val_acc: 0.9407\n",
      "Epoch 13/20\n",
      "1257/1257 [==============================] - 0s 182us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.2138 - val_acc: 0.9463\n",
      "Epoch 14/20\n",
      "1257/1257 [==============================] - 0s 181us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.2191 - val_acc: 0.9463\n",
      "Epoch 15/20\n",
      "1257/1257 [==============================] - 0s 173us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2328 - val_acc: 0.9370\n",
      "Epoch 16/20\n",
      "1257/1257 [==============================] - 0s 166us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2248 - val_acc: 0.9407\n",
      "Epoch 17/20\n",
      "1257/1257 [==============================] - 0s 163us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.2262 - val_acc: 0.9389\n",
      "Epoch 18/20\n",
      "1257/1257 [==============================] - 0s 162us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2265 - val_acc: 0.9389\n",
      "Epoch 19/20\n",
      "1257/1257 [==============================] - 0s 163us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2309 - val_acc: 0.9389\n",
      "Epoch 20/20\n",
      "1257/1257 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2282 - val_acc: 0.9389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f50b4235f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y_cat,epochs=20,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes=datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'DESCR', 'feature_names', 'data_filename', 'target_filename'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=diabetes.data,diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100,activation='relu',input_shape=(10,)))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 309 samples, validate on 133 samples\n",
      "Epoch 1/1000\n",
      "309/309 [==============================] - 1s 3ms/step - loss: 28370.4647 - val_loss: 30613.3370\n",
      "Epoch 2/1000\n",
      "309/309 [==============================] - 0s 140us/step - loss: 28304.7975 - val_loss: 30517.6391\n",
      "Epoch 3/1000\n",
      "309/309 [==============================] - 0s 116us/step - loss: 28186.3154 - val_loss: 30343.4642\n",
      "Epoch 4/1000\n",
      "309/309 [==============================] - 0s 109us/step - loss: 27979.9284 - val_loss: 30043.0045\n",
      "Epoch 5/1000\n",
      "309/309 [==============================] - 0s 95us/step - loss: 27636.2448 - val_loss: 29559.1473\n",
      "Epoch 6/1000\n",
      "309/309 [==============================] - 0s 103us/step - loss: 27096.1545 - val_loss: 28829.4698\n",
      "Epoch 7/1000\n",
      "309/309 [==============================] - 0s 118us/step - loss: 26296.6578 - val_loss: 27777.6762\n",
      "Epoch 8/1000\n",
      "309/309 [==============================] - 0s 116us/step - loss: 25188.1076 - val_loss: 26344.6908\n",
      "Epoch 9/1000\n",
      "309/309 [==============================] - 0s 113us/step - loss: 23700.5222 - val_loss: 24499.3565\n",
      "Epoch 10/1000\n",
      "309/309 [==============================] - 0s 98us/step - loss: 21836.9021 - val_loss: 22215.9510\n",
      "Epoch 11/1000\n",
      "309/309 [==============================] - 0s 101us/step - loss: 19652.9420 - val_loss: 19545.2585\n",
      "Epoch 12/1000\n",
      "309/309 [==============================] - 0s 105us/step - loss: 17085.1099 - val_loss: 16657.9777\n",
      "Epoch 13/1000\n",
      "309/309 [==============================] - 0s 102us/step - loss: 14376.1382 - val_loss: 13674.3246\n",
      "Epoch 14/1000\n",
      "309/309 [==============================] - 0s 109us/step - loss: 11763.7227 - val_loss: 10727.5608\n",
      "Epoch 15/1000\n",
      "309/309 [==============================] - 0s 106us/step - loss: 9226.8270 - val_loss: 8188.3732\n",
      "Epoch 16/1000\n",
      "309/309 [==============================] - 0s 104us/step - loss: 7148.8376 - val_loss: 6197.4299\n",
      "Epoch 17/1000\n",
      "309/309 [==============================] - 0s 100us/step - loss: 5722.6314 - val_loss: 4809.7094\n",
      "Epoch 18/1000\n",
      "309/309 [==============================] - 0s 102us/step - loss: 4743.8761 - val_loss: 4069.4794\n",
      "Epoch 19/1000\n",
      "309/309 [==============================] - 0s 86us/step - loss: 4312.4537 - val_loss: 3727.3446\n",
      "Epoch 20/1000\n",
      "309/309 [==============================] - 0s 99us/step - loss: 4106.8275 - val_loss: 3588.2535\n",
      "Epoch 21/1000\n",
      "309/309 [==============================] - 0s 95us/step - loss: 4010.7876 - val_loss: 3508.7979\n",
      "Epoch 22/1000\n",
      "309/309 [==============================] - 0s 101us/step - loss: 3956.9093 - val_loss: 3442.4256\n",
      "Epoch 23/1000\n",
      "309/309 [==============================] - 0s 117us/step - loss: 3890.9119 - val_loss: 3391.2573\n",
      "Epoch 24/1000\n",
      "309/309 [==============================] - ETA: 0s - loss: 5104.44 - 0s 120us/step - loss: 3834.5397 - val_loss: 3344.4934\n",
      "Epoch 25/1000\n",
      "309/309 [==============================] - 0s 112us/step - loss: 3789.4863 - val_loss: 3298.5212\n",
      "Epoch 26/1000\n",
      "309/309 [==============================] - 0s 115us/step - loss: 3739.6950 - val_loss: 3259.5772\n",
      "Epoch 27/1000\n",
      "309/309 [==============================] - 0s 118us/step - loss: 3700.7756 - val_loss: 3225.7416\n",
      "Epoch 28/1000\n",
      "309/309 [==============================] - 0s 112us/step - loss: 3663.2919 - val_loss: 3188.2053\n",
      "Epoch 29/1000\n",
      "309/309 [==============================] - 0s 107us/step - loss: 3623.0234 - val_loss: 3158.5329\n",
      "Epoch 30/1000\n",
      "309/309 [==============================] - 0s 117us/step - loss: 3591.1436 - val_loss: 3131.4175\n",
      "Epoch 31/1000\n",
      "309/309 [==============================] - 0s 117us/step - loss: 3555.6525 - val_loss: 3100.4219\n",
      "Epoch 32/1000\n",
      "309/309 [==============================] - 0s 125us/step - loss: 3528.6105 - val_loss: 3072.9607\n",
      "Epoch 33/1000\n",
      "309/309 [==============================] - 0s 122us/step - loss: 3495.4311 - val_loss: 3049.3147\n",
      "Epoch 34/1000\n",
      "309/309 [==============================] - 0s 104us/step - loss: 3468.5537 - val_loss: 3027.0412\n",
      "Epoch 35/1000\n",
      "309/309 [==============================] - 0s 101us/step - loss: 3441.8677 - val_loss: 3006.1410\n",
      "Epoch 36/1000\n",
      "309/309 [==============================] - 0s 85us/step - loss: 3416.6928 - val_loss: 2986.3268\n",
      "Epoch 37/1000\n",
      "309/309 [==============================] - 0s 86us/step - loss: 3393.1916 - val_loss: 2967.9634\n",
      "Epoch 38/1000\n",
      "309/309 [==============================] - 0s 98us/step - loss: 3371.5944 - val_loss: 2949.3940\n",
      "Epoch 39/1000\n",
      "309/309 [==============================] - 0s 88us/step - loss: 3349.3717 - val_loss: 2932.5752\n",
      "Epoch 40/1000\n",
      "309/309 [==============================] - 0s 110us/step - loss: 3325.8947 - val_loss: 2917.7472\n",
      "Epoch 41/1000\n",
      "309/309 [==============================] - 0s 117us/step - loss: 3307.4538 - val_loss: 2903.0100\n",
      "Epoch 42/1000\n",
      "309/309 [==============================] - 0s 117us/step - loss: 3288.0580 - val_loss: 2890.8043\n",
      "Epoch 43/1000\n",
      "309/309 [==============================] - 0s 122us/step - loss: 3271.0224 - val_loss: 2878.7077\n",
      "Epoch 44/1000\n",
      "309/309 [==============================] - 0s 124us/step - loss: 3252.8107 - val_loss: 2867.0563\n",
      "Epoch 45/1000\n",
      "309/309 [==============================] - 0s 108us/step - loss: 3239.6332 - val_loss: 2855.1238\n",
      "Epoch 46/1000\n",
      "309/309 [==============================] - 0s 113us/step - loss: 3223.2562 - val_loss: 2844.7968\n",
      "Epoch 47/1000\n",
      "309/309 [==============================] - 0s 82us/step - loss: 3210.9542 - val_loss: 2834.1340\n",
      "Epoch 48/1000\n",
      "309/309 [==============================] - 0s 103us/step - loss: 3193.4687 - val_loss: 2826.3484\n",
      "Epoch 49/1000\n",
      "309/309 [==============================] - 0s 113us/step - loss: 3189.6194 - val_loss: 2826.0948\n",
      "Epoch 50/1000\n",
      "309/309 [==============================] - 0s 108us/step - loss: 3169.0699 - val_loss: 2811.6462\n",
      "Epoch 51/1000\n",
      "309/309 [==============================] - 0s 111us/step - loss: 3157.7339 - val_loss: 2803.4312\n",
      "Epoch 52/1000\n",
      "309/309 [==============================] - 0s 118us/step - loss: 3144.8706 - val_loss: 2802.2323\n",
      "Epoch 53/1000\n",
      "309/309 [==============================] - 0s 94us/step - loss: 3131.8029 - val_loss: 2797.1769\n",
      "Epoch 54/1000\n",
      "309/309 [==============================] - 0s 119us/step - loss: 3121.3411 - val_loss: 2788.8202\n",
      "Epoch 55/1000\n",
      "309/309 [==============================] - 0s 115us/step - loss: 3109.7552 - val_loss: 2780.1273\n",
      "Epoch 56/1000\n",
      "309/309 [==============================] - 0s 100us/step - loss: 3103.5271 - val_loss: 2774.0102\n",
      "Epoch 57/1000\n",
      "309/309 [==============================] - 0s 141us/step - loss: 3105.2113 - val_loss: 2768.5631\n",
      "Epoch 58/1000\n",
      "309/309 [==============================] - 0s 98us/step - loss: 3086.9098 - val_loss: 2768.6224\n",
      "Epoch 59/1000\n",
      "309/309 [==============================] - 0s 91us/step - loss: 3077.4094 - val_loss: 2767.2612\n",
      "Epoch 60/1000\n",
      "309/309 [==============================] - 0s 97us/step - loss: 3071.3038 - val_loss: 2767.2992\n",
      "Epoch 61/1000\n",
      "309/309 [==============================] - 0s 97us/step - loss: 3061.5118 - val_loss: 2762.2417\n",
      "Epoch 62/1000\n",
      "309/309 [==============================] - 0s 124us/step - loss: 3056.0219 - val_loss: 2756.3916\n",
      "Epoch 63/1000\n",
      "309/309 [==============================] - 0s 107us/step - loss: 3050.2039 - val_loss: 2754.5415\n",
      "Epoch 64/1000\n",
      "309/309 [==============================] - 0s 121us/step - loss: 3050.2300 - val_loss: 2748.6645\n",
      "Epoch 65/1000\n",
      "309/309 [==============================] - 0s 112us/step - loss: 3038.4844 - val_loss: 2753.8865\n",
      "Epoch 66/1000\n",
      "309/309 [==============================] - 0s 108us/step - loss: 3033.1330 - val_loss: 2752.7315\n",
      "Epoch 67/1000\n",
      "309/309 [==============================] - 0s 104us/step - loss: 3028.5929 - val_loss: 2748.2075\n",
      "Epoch 68/1000\n",
      "309/309 [==============================] - 0s 111us/step - loss: 3023.9567 - val_loss: 2747.2762\n",
      "Epoch 69/1000\n",
      "309/309 [==============================] - 0s 95us/step - loss: 3022.2270 - val_loss: 2747.7661\n",
      "Epoch 70/1000\n",
      "309/309 [==============================] - 0s 94us/step - loss: 3012.7463 - val_loss: 2743.8754\n",
      "Epoch 71/1000\n",
      "309/309 [==============================] - 0s 90us/step - loss: 3009.8408 - val_loss: 2743.4785\n",
      "Epoch 72/1000\n",
      "309/309 [==============================] - 0s 106us/step - loss: 3012.9812 - val_loss: 2750.4220\n",
      "Epoch 73/1000\n",
      "309/309 [==============================] - 0s 103us/step - loss: 3006.3667 - val_loss: 2740.3740\n",
      "Epoch 74/1000\n",
      "309/309 [==============================] - 0s 110us/step - loss: 3004.9877 - val_loss: 2737.8220\n",
      "Epoch 75/1000\n",
      "309/309 [==============================] - 0s 117us/step - loss: 2995.9779 - val_loss: 2743.6405\n",
      "Epoch 76/1000\n",
      "309/309 [==============================] - 0s 109us/step - loss: 2993.7469 - val_loss: 2745.7419\n",
      "Epoch 77/1000\n",
      "309/309 [==============================] - 0s 116us/step - loss: 2990.7893 - val_loss: 2741.6789\n",
      "Epoch 78/1000\n",
      "309/309 [==============================] - 0s 92us/step - loss: 2987.3383 - val_loss: 2740.3657\n",
      "Epoch 79/1000\n",
      "309/309 [==============================] - 0s 119us/step - loss: 2987.6658 - val_loss: 2751.6119\n",
      "Epoch 80/1000\n",
      "309/309 [==============================] - 0s 113us/step - loss: 2980.6639 - val_loss: 2749.5431\n",
      "Epoch 81/1000\n",
      "309/309 [==============================] - 0s 112us/step - loss: 2979.1090 - val_loss: 2741.7714\n",
      "Epoch 82/1000\n",
      "309/309 [==============================] - 0s 112us/step - loss: 2975.6217 - val_loss: 2745.2958\n",
      "Epoch 83/1000\n",
      "309/309 [==============================] - 0s 121us/step - loss: 2974.5661 - val_loss: 2750.1793\n",
      "Epoch 84/1000\n",
      "309/309 [==============================] - 0s 140us/step - loss: 2970.5282 - val_loss: 2745.4088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258069a65c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,validation_split=0.3,shuffle=True,epochs=1000,callbacks=[EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5929.884896910383"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y,[np.mean(y)]*len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5387080452015517"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-2735/5929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits=datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=digits.data\n",
    "y=digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat=to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1257 samples, validate on 540 samples\n",
      "Epoch 1/1000\n",
      "1257/1257 [==============================] - 1s 404us/step - loss: 6.1299 - acc: 0.1822 - val_loss: 3.9679 - val_acc: 0.3111\n",
      "Epoch 2/1000\n",
      "1257/1257 [==============================] - 0s 76us/step - loss: 2.1666 - acc: 0.5068 - val_loss: 1.7090 - val_acc: 0.5630\n",
      "Epoch 3/1000\n",
      "1257/1257 [==============================] - 0s 75us/step - loss: 0.7801 - acc: 0.7279 - val_loss: 1.1793 - val_acc: 0.7019\n",
      "Epoch 4/1000\n",
      "1257/1257 [==============================] - 0s 81us/step - loss: 0.4531 - acc: 0.8560 - val_loss: 0.9813 - val_acc: 0.7611\n",
      "Epoch 5/1000\n",
      "1257/1257 [==============================] - 0s 80us/step - loss: 0.3096 - acc: 0.8958 - val_loss: 0.8973 - val_acc: 0.7852\n",
      "Epoch 6/1000\n",
      "1257/1257 [==============================] - 0s 75us/step - loss: 0.2346 - acc: 0.9300 - val_loss: 0.8104 - val_acc: 0.8074\n",
      "Epoch 7/1000\n",
      "1257/1257 [==============================] - 0s 120us/step - loss: 0.1870 - acc: 0.9499 - val_loss: 0.7681 - val_acc: 0.8259\n",
      "Epoch 8/1000\n",
      "1257/1257 [==============================] - 0s 156us/step - loss: 0.1492 - acc: 0.9594 - val_loss: 0.7050 - val_acc: 0.8407\n",
      "Epoch 9/1000\n",
      "1257/1257 [==============================] - 0s 176us/step - loss: 0.1212 - acc: 0.9690 - val_loss: 0.6834 - val_acc: 0.8463\n",
      "Epoch 10/1000\n",
      "1257/1257 [==============================] - 0s 167us/step - loss: 0.1048 - acc: 0.9714 - val_loss: 0.6332 - val_acc: 0.8574\n",
      "Epoch 11/1000\n",
      "1257/1257 [==============================] - 0s 148us/step - loss: 0.0911 - acc: 0.9761 - val_loss: 0.6130 - val_acc: 0.8611\n",
      "Epoch 12/1000\n",
      "1257/1257 [==============================] - 0s 167us/step - loss: 0.0805 - acc: 0.9849 - val_loss: 0.5900 - val_acc: 0.8593\n",
      "Epoch 13/1000\n",
      "1257/1257 [==============================] - 0s 166us/step - loss: 0.0698 - acc: 0.9865 - val_loss: 0.5720 - val_acc: 0.8648\n",
      "Epoch 14/1000\n",
      "1257/1257 [==============================] - 0s 171us/step - loss: 0.0587 - acc: 0.9873 - val_loss: 0.5461 - val_acc: 0.8704\n",
      "Epoch 15/1000\n",
      "1257/1257 [==============================] - 0s 164us/step - loss: 0.0532 - acc: 0.9889 - val_loss: 0.5487 - val_acc: 0.8778\n",
      "Epoch 16/1000\n",
      "1257/1257 [==============================] - 0s 142us/step - loss: 0.0457 - acc: 0.9912 - val_loss: 0.5342 - val_acc: 0.8778\n",
      "Epoch 17/1000\n",
      "1257/1257 [==============================] - 0s 134us/step - loss: 0.0454 - acc: 0.9905 - val_loss: 0.5157 - val_acc: 0.8815\n",
      "Epoch 18/1000\n",
      "1257/1257 [==============================] - 0s 153us/step - loss: 0.0371 - acc: 0.9920 - val_loss: 0.5165 - val_acc: 0.8833\n",
      "Epoch 19/1000\n",
      "1257/1257 [==============================] - 0s 168us/step - loss: 0.0358 - acc: 0.9944 - val_loss: 0.5022 - val_acc: 0.8815\n",
      "Epoch 20/1000\n",
      "1257/1257 [==============================] - 0s 167us/step - loss: 0.0352 - acc: 0.9928 - val_loss: 0.4927 - val_acc: 0.8815\n",
      "Epoch 21/1000\n",
      "1257/1257 [==============================] - 0s 183us/step - loss: 0.0287 - acc: 0.9936 - val_loss: 0.4968 - val_acc: 0.8852\n",
      "Epoch 22/1000\n",
      "1257/1257 [==============================] - 0s 176us/step - loss: 0.0271 - acc: 0.9968 - val_loss: 0.4869 - val_acc: 0.8852\n",
      "Epoch 23/1000\n",
      "1257/1257 [==============================] - 0s 113us/step - loss: 0.0246 - acc: 0.9968 - val_loss: 0.4770 - val_acc: 0.8833\n",
      "Epoch 24/1000\n",
      "1257/1257 [==============================] - 0s 102us/step - loss: 0.0218 - acc: 0.9984 - val_loss: 0.4779 - val_acc: 0.8889\n",
      "Epoch 25/1000\n",
      "1257/1257 [==============================] - 0s 164us/step - loss: 0.0202 - acc: 0.9976 - val_loss: 0.4756 - val_acc: 0.8852\n",
      "Epoch 26/1000\n",
      "1257/1257 [==============================] - 0s 171us/step - loss: 0.0183 - acc: 0.9984 - val_loss: 0.4676 - val_acc: 0.8870\n",
      "Epoch 27/1000\n",
      "1257/1257 [==============================] - 0s 123us/step - loss: 0.0168 - acc: 0.9992 - val_loss: 0.4697 - val_acc: 0.8889\n",
      "Epoch 28/1000\n",
      "1257/1257 [==============================] - 0s 77us/step - loss: 0.0180 - acc: 0.9984 - val_loss: 0.4756 - val_acc: 0.8870\n",
      "Epoch 29/1000\n",
      "1257/1257 [==============================] - 0s 122us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.4566 - val_acc: 0.8926\n",
      "Epoch 30/1000\n",
      "1257/1257 [==============================] - 0s 138us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.4552 - val_acc: 0.8926\n",
      "Epoch 31/1000\n",
      "1257/1257 [==============================] - 0s 124us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.4545 - val_acc: 0.8944\n",
      "Epoch 32/1000\n",
      "1257/1257 [==============================] - 0s 123us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.4474 - val_acc: 0.8944\n",
      "Epoch 33/1000\n",
      "1257/1257 [==============================] - 0s 136us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.4496 - val_acc: 0.8926\n",
      "Epoch 34/1000\n",
      "1257/1257 [==============================] - 0s 156us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.4410 - val_acc: 0.8944\n",
      "Epoch 35/1000\n",
      "1257/1257 [==============================] - 0s 160us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4438 - val_acc: 0.8944\n",
      "Epoch 36/1000\n",
      "1257/1257 [==============================] - 0s 158us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.4390 - val_acc: 0.8926\n",
      "Epoch 37/1000\n",
      "1257/1257 [==============================] - 0s 156us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4402 - val_acc: 0.8926\n",
      "Epoch 38/1000\n",
      "1257/1257 [==============================] - 0s 162us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4384 - val_acc: 0.8926\n",
      "Epoch 39/1000\n",
      "1257/1257 [==============================] - 0s 156us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4359 - val_acc: 0.8944\n",
      "Epoch 40/1000\n",
      "1257/1257 [==============================] - 0s 151us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4388 - val_acc: 0.8963\n",
      "Epoch 41/1000\n",
      "1257/1257 [==============================] - 0s 147us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4378 - val_acc: 0.9019\n",
      "Epoch 42/1000\n",
      "1257/1257 [==============================] - 0s 150us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4355 - val_acc: 0.8981\n",
      "Epoch 43/1000\n",
      "1257/1257 [==============================] - 0s 142us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4362 - val_acc: 0.8963\n",
      "Epoch 44/1000\n",
      "1257/1257 [==============================] - 0s 146us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4402 - val_acc: 0.9037\n",
      "Epoch 45/1000\n",
      "1257/1257 [==============================] - 0s 151us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.4379 - val_acc: 0.8963\n",
      "Epoch 46/1000\n",
      "1257/1257 [==============================] - 0s 156us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.4368 - val_acc: 0.9056\n",
      "Epoch 47/1000\n",
      "1257/1257 [==============================] - 0s 159us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.4376 - val_acc: 0.9037\n",
      "Epoch 48/1000\n",
      "1257/1257 [==============================] - 0s 160us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.4326 - val_acc: 0.9019\n",
      "Epoch 49/1000\n",
      "1257/1257 [==============================] - 0s 161us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.4337 - val_acc: 0.9000\n",
      "Epoch 50/1000\n",
      "1257/1257 [==============================] - 0s 158us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.4318 - val_acc: 0.9000\n",
      "Epoch 51/1000\n",
      "1257/1257 [==============================] - 0s 148us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.4371 - val_acc: 0.9074\n",
      "Epoch 52/1000\n",
      "1257/1257 [==============================] - 0s 151us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4321 - val_acc: 0.9019\n",
      "Epoch 53/1000\n",
      "1257/1257 [==============================] - 0s 148us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4341 - val_acc: 0.9019\n",
      "Epoch 54/1000\n",
      "1257/1257 [==============================] - 0s 145us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.4310 - val_acc: 0.9037\n",
      "Epoch 55/1000\n",
      "1257/1257 [==============================] - 0s 146us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.4345 - val_acc: 0.9037\n",
      "Epoch 56/1000\n",
      "1257/1257 [==============================] - 0s 141us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.4358 - val_acc: 0.9037\n",
      "Epoch 57/1000\n",
      "1257/1257 [==============================] - 0s 142us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.4367 - val_acc: 0.9056\n",
      "Epoch 58/1000\n",
      "1257/1257 [==============================] - 0s 141us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.4359 - val_acc: 0.9037\n",
      "Epoch 59/1000\n",
      "1257/1257 [==============================] - 0s 141us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.4351 - val_acc: 0.9093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "1257/1257 [==============================] - 0s 141us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4322 - val_acc: 0.9056\n",
      "Epoch 61/1000\n",
      "1257/1257 [==============================] - 0s 142us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.4332 - val_acc: 0.9111\n",
      "Epoch 62/1000\n",
      "1257/1257 [==============================] - 0s 145us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.4335 - val_acc: 0.9074\n",
      "Epoch 63/1000\n",
      "1257/1257 [==============================] - 0s 141us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.4347 - val_acc: 0.9111\n",
      "Epoch 64/1000\n",
      "1257/1257 [==============================] - 0s 142us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.4337 - val_acc: 0.9093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e61787f60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(40,activation='relu',input_shape=(64,)))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x,y_cat,validation_split=0.3,shuffle=True,epochs=1000,callbacks=[EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-d12225c9b9bf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-49-d12225c9b9bf>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    5 neuron 1 layer - 0.5939\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "5 neuron 1 layer - 0.5939\n",
    "5 neuron 2 layer - 0.6710\n",
    "10 neuron 1 layer -0.4402\n",
    "20 neuron 1 layer - 0.3258\n",
    "40 neuron 1 layer - 0.3107\n",
    "\n",
    "0- 0.7  0.6\n",
    "1- 0.3   0.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-50-99983191209b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-50-99983191209b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    64 columns\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "64 columns\n",
    "\n",
    "100 neuron - 1 layer - 6400 weights +100*1 bias =6500\n",
    "100 neuron - 2 layer - 10000 wights +100*1 bias = 10100\n",
    "10 neuron - 3 layer - 1000 wights + 10*1 bias = 1010\n",
    "\n",
    "1760 values trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 17,610\n",
      "Trainable params: 17,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
